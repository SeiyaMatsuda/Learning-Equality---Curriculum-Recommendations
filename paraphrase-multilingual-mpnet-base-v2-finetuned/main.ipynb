{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1674280861175,"user":{"displayName":"松田征也","userId":"08531742653822505465"},"user_tz":-540},"id":"dvDJamMh8_Fj"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1032,"status":"ok","timestamp":1674280862201,"user":{"displayName":"松田征也","userId":"08531742653822505465"},"user_tz":-540},"id":"8Y9BEKPDDOuC","outputId":"69ee4889-3b82-4266-cda6-40b6397881cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Jan 21 06:01:02 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   26C    P0    50W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11857,"status":"ok","timestamp":1674280874057,"user":{"displayName":"松田征也","userId":"08531742653822505465"},"user_tz":-540},"id":"TwsDJWeb9Fq4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,\u003c0.14,\u003e=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.10.0-\u003etransformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (2022.12.7)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: chardet\u003c5,\u003e=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (4.0.0)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fuzzywuzzy\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Installing collected packages: fuzzywuzzy\n","Successfully installed fuzzywuzzy-0.18.0\n"]}],"source":["!pip install -U transformers\n","!pip install sentencepiece\n","!pip install -U fuzzywuzzy"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3641,"status":"ok","timestamp":1674280877693,"user":{"displayName":"松田征也","userId":"08531742653822505465"},"user_tz":-540},"id":"fQODZQ6b9LPk"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_lightning==1.8.6\n","  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 KB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lightning-utilities!=0.4.0,\u003e=0.3.0\n","  Downloading lightning_utilities-0.5.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: tqdm\u003e=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.8.6) (4.64.1)\n","Collecting tensorboardX\u003e=2.2\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML\u003e=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.8.6) (6.0)\n","Requirement already satisfied: torch\u003e=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.8.6) (1.13.1+cu116)\n","Collecting torchmetrics\u003e=0.7.0\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.8.6) (1.21.6)\n","Requirement already satisfied: typing-extensions\u003e=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.8.6) (4.4.0)\n","Requirement already satisfied: packaging\u003e=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.8.6) (21.3)\n","Requirement already satisfied: fsspec[http]\u003e2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning==1.8.6) (2022.11.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (2.25.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (3.8.3)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging\u003e=17.0-\u003epytorch_lightning==1.8.6) (3.0.9)\n","Requirement already satisfied: protobuf\u003c=3.20.1,\u003e=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX\u003e=2.2-\u003epytorch_lightning==1.8.6) (3.19.6)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (1.8.2)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (22.2.0)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (1.3.1)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (4.0.2)\n","Requirement already satisfied: charset-normalizer\u003c3.0,\u003e=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (2.1.1)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (1.3.3)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (6.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests-\u003efsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (2022.12.7)\n","Requirement already satisfied: chardet\u003c5,\u003e=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests-\u003efsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (4.0.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.8/dist-packages (from requests-\u003efsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (2.10)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests-\u003efsspec[http]\u003e2021.06.0-\u003epytorch_lightning==1.8.6) (1.24.3)\n","Installing collected packages: tensorboardX, torchmetrics, lightning-utilities, pytorch_lightning\n","Successfully installed lightning-utilities-0.5.0 pytorch_lightning-1.8.6 tensorboardX-2.5.1 torchmetrics-0.11.0\n"]}],"source":["!pip install pytorch_lightning==1.8.6"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":765041,"status":"error","timestamp":1674281642730,"user":{"displayName":"松田征也","userId":"08531742653822505465"},"user_tz":-540},"id":"ZvxBv63B8rMm"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cfunction is_available at 0x7fa42aee4e50\u003e\n","================================== Start Running =====================================\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2cdb4aa78a44ed18301e6587c453306","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/402 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04233162ca624cc3bfc1ffc28ef0971b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/723 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50ca9f93f15f4ded84c9e9cd6a709e7b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/5.07M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f8cecd1a4f240a5bfe24f11db27e325","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/9.08M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fae254723ce47c7b5598aad5bff9844","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/239 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:lightning_lite.utilities.seed:Global seed set to 42\n"]},{"name":"stdout","output_type":"stream","text":["================================== Prepare Data for fold0 =====================================\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27976e00a72843ea992f3e9027aa460f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.11G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=[0])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[0])` instead.\n","  rank_zero_deprecation(\n","INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_0 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"name":"stdout","output_type":"stream","text":["================================== Start Training fold0 =====================================\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name        | Type            | Params\n","------------------------------------------------\n","0 | transformer | XLMRobertaModel | 278 M \n","------------------------------------------------\n","278 M     Trainable params\n","0         Non-trainable params\n","278 M     Total params\n","556.089   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15b16ff59a20493d83a14b3e7eb941f9","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1967d3b22f5843948626b832d3efa9d6","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"535541c4c6244bffa627ddf5a2c581ff","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 870: 'val_loss' reached 3.30817 (best 3.30817), saving model to '/content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_0/epoch=0-step=870-v1.ckpt' as top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"985d0c1fcafb4c46b22eb101bcc59cd2","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 1740: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c481c0b6205436388ab507d54449432","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 2610: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5c8f0c923a84ee99348ec886d1e167a","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 3480: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"476a5c6e154e47a3a08114e739f7c1a7","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 4350: 'val_loss' was not in top 1\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n","INFO:lightning_lite.utilities.seed:Global seed set to 42\n"]},{"name":"stdout","output_type":"stream","text":["best model path:  /content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_0/epoch=0-step=870-v1.ckpt\n","================================== Prepare Data for fold1 =====================================\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_1 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"name":"stdout","output_type":"stream","text":["================================== Start Training fold1 =====================================\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name        | Type            | Params\n","------------------------------------------------\n","0 | transformer | XLMRobertaModel | 278 M \n","------------------------------------------------\n","278 M     Trainable params\n","0         Non-trainable params\n","278 M     Total params\n","556.089   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cdce9928c2884b7b8292c075e7044796","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9702f47487244a138954ebfe6c0af54d","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7393d9e8b75f476c969a2609bd3fc15e","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 874: 'val_loss' reached 3.33907 (best 3.33907), saving model to '/content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_1/epoch=0-step=874.ckpt' as top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6bfc01148a3e431ca71c507a4c8225ee","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 1748: 'val_loss' reached 3.32566 (best 3.32566), saving model to '/content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_1/epoch=1-step=1748.ckpt' as top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6131a971d69408ebcb562b33872b183","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 2622: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc9ade3cfccc4683b829d83c5c1a0876","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 3496: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a61dda6f4e96466ebfe92a9c4fe18edd","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 4370: 'val_loss' was not in top 1\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n","INFO:lightning_lite.utilities.seed:Global seed set to 42\n"]},{"name":"stdout","output_type":"stream","text":["best model path:  /content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_1/epoch=1-step=1748.ckpt\n","================================== Prepare Data for fold2 =====================================\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_2 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"name":"stdout","output_type":"stream","text":["================================== Start Training fold2 =====================================\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name        | Type            | Params\n","------------------------------------------------\n","0 | transformer | XLMRobertaModel | 278 M \n","------------------------------------------------\n","278 M     Trainable params\n","0         Non-trainable params\n","278 M     Total params\n","556.089   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"692c6ad9c0bd41738266e0ad6d6bec6e","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f9aa608e9304d9cb088c306bb2a0929","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16db3a9d5c6c40688c319d54b8ea3449","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 873: 'val_loss' reached 3.21858 (best 3.21858), saving model to '/content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_2/epoch=0-step=873.ckpt' as top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"606a01d2469841e4b4821271bcf4c4fb","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 1746: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8fbfaa7732784d49b06c998797ef2535","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 2619: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9fbc69eff2364dfa800f7d4741ad0a1a","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 3492: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db5eb02fa98f4d6a868c6842d4f12ca2","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 4365: 'val_loss' was not in top 1\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n","INFO:lightning_lite.utilities.seed:Global seed set to 42\n"]},{"name":"stdout","output_type":"stream","text":["best model path:  /content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_2/epoch=0-step=873.ckpt\n","================================== Prepare Data for fold3 =====================================\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_3 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"name":"stdout","output_type":"stream","text":["================================== Start Training fold3 =====================================\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name        | Type            | Params\n","------------------------------------------------\n","0 | transformer | XLMRobertaModel | 278 M \n","------------------------------------------------\n","278 M     Trainable params\n","0         Non-trainable params\n","278 M     Total params\n","556.089   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2199722a9a249fc951cfaf1336184d0","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f46d70fdd69a41338f6bdfc764341e6a","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5196bdea168a46cbbf57972e8c793c2e","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 874: 'val_loss' reached 3.36832 (best 3.36832), saving model to '/content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_3/epoch=0-step=874.ckpt' as top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffa1840559f64329989cc5f8912817ad","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 1748: 'val_loss' reached 3.31174 (best 3.31174), saving model to '/content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_3/epoch=1-step=1748.ckpt' as top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b1b37551ac64b90a1ac17f466a7df72","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 2622: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71e64db88dfc43df8539587526e51093","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 3496: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d3c466bd04e440d902871f51aba25c1","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 4370: 'val_loss' was not in top 1\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n","INFO:lightning_lite.utilities.seed:Global seed set to 42\n"]},{"name":"stdout","output_type":"stream","text":["best model path:  /content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_3/epoch=1-step=1748.ckpt\n","================================== Prepare Data for fold4 =====================================\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_4 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"name":"stdout","output_type":"stream","text":["================================== Start Training fold4 =====================================\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name        | Type            | Params\n","------------------------------------------------\n","0 | transformer | XLMRobertaModel | 278 M \n","------------------------------------------------\n","278 M     Trainable params\n","0         Non-trainable params\n","278 M     Total params\n","556.089   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e88e61c18684121a1fc29939ee7ac00","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22369eade0ea4dc5903f433d65247a7a","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6252a4198bd94bb287f9e1ef58af5f34","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 881: 'val_loss' reached 3.31127 (best 3.31127), saving model to '/content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_4/epoch=0-step=881.ckpt' as top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"019e3f8a99ab47e298320e9804597a82","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 1762: 'val_loss' reached 3.23173 (best 3.23173), saving model to '/content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_4/epoch=1-step=1762.ckpt' as top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b17e16452d8e40efa0b0b945fc7e7ce1","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 2643: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b480f1355bb1459db71d55ad7bc9df1b","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 3524: 'val_loss' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98aab534f627490f826ff5d82442133c","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 4405: 'val_loss' was not in top 1\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n"]},{"name":"stdout","output_type":"stream","text":["best model path:  /content/drive/MyDrive/workspace/Learning_Equality/paraphrase-multilingual-mpnet-base-v2-context/fold_4/epoch=1-step=1762.ckpt\n"]}],"source":["import os\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import pytorch_lightning as pl\n","from transformers import AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.model_selection import KFold\n","from pytorch_lightning.utilities.types import TRAIN_DATALOADERS\n","import random\n","print(torch.cuda.is_available)\n","class CFG:\n","    ROW_DIR = Path('../data/row')\n","    PROCESSED_DIR = Path('../data/processed/train_data')\n","    TOKENIZER = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n","    MODEL = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n","    BATCH_PER_GPU = 256\n","    SEED=42\n","    NUM_EPOCHS=5\n","    LR = 1e-5\n","    NUM_GPUS=1\n","    NUM_JOBS=4\n","    AMP=True\n","\n","def get_train_test_data(train, train_idx):\n","    train[\"fold\"] = -1\n","    # 交差検証 用の番号を振ります。\n","    kf = KFold(n_splits=5, shuffle=True, random_state=CFG.SEED)\n","    for n, (train_index, val_index) in enumerate(kf.split(train_idx)):\n","        train.loc[train_idx[val_index], \"fold\"] = int(n)\n","    train[\"fold\"] = train[\"fold\"]\n","    return train\n","\n","def get_path_list(df):\n","    topics_id2title = {k:v for k, v in zip(df.id.to_list(), df.title.to_list())}\n","    topics_id2description = {k:v for k, v in zip(df.id.to_list(), df.description.to_list())}\n","    topics_id2parents = {k:v for k, v in zip(df.id.to_list(), df.parent.to_list())}\n","    path_list = []\n","    for id in df.id.to_list():\n","        res_list = []\n","        while True:\n","            res_list.append(topics_id2title[id])\n","            id = topics_id2parents[id]\n","            if id==\"\":\n","                break\n","        path_list.append(\" | \".join(res_list[::-1][:-1]))\n","    return path_list\n","    \n","class MyDataset(Dataset):\n","    def __init__(self, tokenizer, df, topics_df, contetn_df):\n","        self.all_topics_id = df.topic_id.to_numpy()\n","        self.all_content_id = df.content_id.to_numpy()\n","        self.topics_title_dict = {id:title for id, title in zip(topics_df.id, topics_df.title)}\n","        self.topics_path_dict = {id:path for id, path in zip(topics_df.id, topics_df.path)}\n","        self.content_title_dict = {id:title for id, title in zip(contetn_df.id, contetn_df.title)}\n","        self.all_topics_title = [self.topics_title_dict[id] for id in self.all_topics_id]\n","        self.all_topics_path = [self.topics_path_dict[id] for id in self.all_topics_id]\n","        self.all_content_title = [self.content_title_dict[id] for id in self.all_content_id]\n","        self.tokenizer = tokenizer\n","    def __len__(self):\n","        return len(self.all_topics_id)\n","    def __getitem__(self, idx):\n","        topic_id = self.all_topics_id[idx]\n","        content_id = self.all_content_id[idx]\n","        topic_text = self.all_topics_title[idx]\n","        topic_path = self.all_topics_path[idx]\n","        topic_rep = topic_text + \"\u003c|=t_sep=|\u003e\" + topic_path\n","        content_text = self.all_content_title[idx]\n","        topic_inputs =  self.tokenizer.encode_plus(\n","        topic_rep, \n","        return_tensors = None, \n","        add_special_tokens = True\n","        )\n","        content_inputs =  self.tokenizer.encode_plus(\n","        content_text, \n","        return_tensors = None, \n","        add_special_tokens = True\n","        )\n","        topic_input_ids = topic_inputs['input_ids']\n","        topic_attention_mask = topic_inputs['attention_mask']\n","        content_input_ids = content_inputs['input_ids']\n","        content_attention_mask = content_inputs['attention_mask']\n","        return {\n","                'topic_input_ids':topic_input_ids,\n","                'topic_attention_mask':topic_attention_mask,\n","                'content_input_ids':content_input_ids,\n","                'content_attention_mask':content_attention_mask,\n","                }\n","\n","def collate_fn(batch, tokenizer):\n","    \"\"\"\n","    自然言語処理タスク向けのcollate_fn\n","    \"\"\"\n","    topic_max_len = max([len(b['topic_input_ids']) for b in batch])\n","    content_max_len = max([len(b['content_input_ids']) for b in batch])\n","    # バッチ内の各要素から文章とラベルを取得\n","    topic_input_ids = [b['topic_input_ids']+[tokenizer.pad_token_id] * (topic_max_len-len(b['topic_input_ids'])) for b in batch]\n","    topic_attention_mask = [b['topic_attention_mask']+[0] * (topic_max_len-len(b['topic_attention_mask'])) for b in batch]\n","    content_input_ids = [b['content_input_ids']+[tokenizer.pad_token_id] * (content_max_len-len(b['content_input_ids'])) for b in batch]\n","    content_attention_mask = [b['content_attention_mask']+[0] * (content_max_len-len(b['content_attention_mask'])) for b in batch]\n","    return {\n","              'topic_input_ids':torch.tensor(topic_input_ids, dtype=torch.long),\n","              'topic_attention_mask':torch.tensor(topic_attention_mask, dtype=torch.long),\n","              'content_input_ids':torch.tensor(content_input_ids, dtype=torch.long),\n","              'content_attention_mask':torch.tensor(content_attention_mask, dtype=torch.long),\n","              }\n","    \n","class FeedbackModel(pl.LightningModule):\n","    def __init__(self, tokenizer,  model_name, learning_rate, num_train_steps, steps_per_epoch):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        \n","        self.tokenizer = tokenizer\n","        self.model_name = model_name\n","        self.learning_rate = learning_rate\n","        self.num_train_steps = num_train_steps\n","        self.steps_per_epoch = steps_per_epoch\n","        self.step_scheduler_after = \"batch\"\n","        \n","        config = AutoConfig.from_pretrained(model_name)\n","\n","        \n","        self.transformer = AutoModel.from_pretrained(model_name, config=config)\n","        self.transformer.resize_token_embeddings(len(self.tokenizer))\n","        \n","    def forward(self, ids1, mask1, ids2, mask2):\n","\n","        transformer_out1 = self.transformer(ids1, mask1)\n","        transformer_out2 = self.transformer(ids2, mask2)\n","        sequence_output1 = transformer_out1.last_hidden_state.mean(1)\n","        sequence_output2 = transformer_out2.last_hidden_state.mean(1)\n","        loss = self.loss(sequence_output1, sequence_output2)\n","        return sequence_output1, sequence_output2, loss\n","    \n","    def loss(self, embeddings_a, embeddings_b):\n","        loss = self.MultipleNegativeRankingLoss(embeddings_a, embeddings_b)\n","        return loss\n","    \n","\n","    def ContrastiveLoss(self, x1, x2, label, margin: float = 1.0):\n","        \"\"\"\n","        Computes Contrastive Loss\n","        \"\"\"\n","\n","        dist = torch.nn.functional.pairwise_distance(x1, x2)\n","        loss = (1 - label) * torch.pow(dist, 2) \\\n","            + (label) * torch.pow(torch.clamp(margin - dist, min=0.0), 2)\n","        loss = torch.mean(loss)\n","        return loss\n","    \n","    def MultipleNegativeRankingLoss(self, embeddings_a:torch.Tensor, embeddings_b:torch.Tensor):\n","        \"\"\"\n","        Computes MultipleNegativeRankingLoss\n","        \"\"\"\n","\n","        scores = torch.matmul(embeddings_a, embeddings_b.t())\n","        diagonal_mean = torch.mean(torch.diag(scores))\n","        mean_log_row_sum_exp = torch.mean(torch.logsumexp(scores, dim=1))\n","        return -diagonal_mean + mean_log_row_sum_exp\n","    \n","    def training_step(self, batch, batch_idx):\n","        ids1, mask1, ids2, mask2 = batch['topic_input_ids'], batch['topic_attention_mask'], batch['content_input_ids'], batch['content_attention_mask']\n","        sequence_output1, sequence_output2, loss = self.forward(ids1=ids1, mask1=mask1,ids2=ids2, mask2=mask2)\n","        self.log(\"train_loss\", loss, on_step=True, logger=True, prog_bar=True)\n","        return loss\n","    \n","    def validation_step(self, batch, batch_idx):\n","        ids1, mask1, ids2, mask2 = batch['topic_input_ids'], batch['topic_attention_mask'], batch['content_input_ids'], batch['content_attention_mask']\n","        sequence_output1, sequence_output2, loss = self.forward(ids1=ids1, mask1=mask1,ids2=ids2, mask2=mask2)\n","        self.log('val_loss', loss, on_step=True, logger=True, prog_bar=True)\n","        return {'val_loss': loss}\n","        \n","    def validation_epoch_end(self, val_step_outputs):\n","        val_loss = sum([val['val_loss'] for val in val_step_outputs])/len([val['val_loss'] for val in val_step_outputs])\n","        self.log(\"val_loss\", val_loss, on_epoch=True, logger=True, prog_bar=False)\n","        return {'val_loss':val_loss}\n","    \n","    def configure_optimizers(self):\n","        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n","        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * self.num_train_steps), num_training_steps=self.num_train_steps)\n","        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\"}]\n","\n","def train_fold(df, tokenizer, topics_df, content_df, fold):\n","    pl.seed_everything(CFG.SEED)\n","\n","    dirpath = f'./fold_{fold}'\n","    os.makedirs(dirpath, exist_ok=True)\n","\n","    print(f'================================== Prepare Data for fold{fold} =====================================')\n","    train_samples = df[df[\"fold\"] != fold].reset_index(drop=True)\n","    valid_samples = df[df[\"fold\"] == fold].reset_index(drop=True)\n","    train_dataset = MyDataset(tokenizer, train_samples, topics_df, content_df)\n","    valid_dataset = MyDataset(tokenizer, valid_samples, topics_df, content_df)\n","    func = lambda x:collate_fn(x, tokenizer)\n","\n","    train_dataloader = DataLoader(train_dataset, batch_size=CFG.BATCH_PER_GPU, \n","                                  collate_fn=func,\n","                                  shuffle=True, num_workers=CFG.NUM_JOBS, drop_last=True)\n","    val_dataloader = DataLoader(valid_dataset, batch_size=CFG.BATCH_PER_GPU, \n","                                collate_fn=func,\n","                                shuffle=False, num_workers=CFG.NUM_JOBS, drop_last=False)\n","\n","    total_batch_size = CFG.BATCH_PER_GPU * CFG.NUM_GPUS\n","    steps_per_epoch = int(len(train_dataset) // total_batch_size)\n","    num_train_step = int(steps_per_epoch * CFG.NUM_EPOCHS)\n","    lightning_model = FeedbackModel(tokenizer, CFG.MODEL, CFG.LR, num_train_step, steps_per_epoch)\n","\n","    checkpoint = pl.callbacks.ModelCheckpoint(\n","        monitor=\"val_loss\",\n","        mode=\"min\",\n","        save_top_k=1,\n","        save_weights_only=True,\n","        verbose=True,\n","        dirpath=dirpath,\n","    )\n","\n","    lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n","\n","    early_stopping = pl.callbacks.EarlyStopping(\n","        monitor=\"val_loss\",\n","        min_delta=0.0,\n","        patience=4,\n","        mode=\"min\",\n","    )\n","\n","    call_backs = [checkpoint, lr_monitor, early_stopping]\n","\n","    trainer = pl.Trainer(\n","        max_epochs=CFG.NUM_EPOCHS,\n","        callbacks=call_backs,\n","        gpus=-1 if CFG.NUM_GPUS != 1 else [0],\n","        strategy=\"ddp\" if CFG.NUM_GPUS != 1 else None,\n","        precision = 16 if CFG.AMP else 32,\n","        amp_backend = \"native\",\n","    )\n","    print(f'================================== Start Training fold{fold} =====================================')\n","    trainer.fit(lightning_model, train_dataloader, val_dataloader)\n","\n","    best_model_path = checkpoint.best_model_path\n","    print(\"best model path: \", best_model_path)\n","    \n","def main():\n","    print(f\"================================== Start Running =====================================\")\n","    topics_df = pd.read_csv(CFG.ROW_DIR / 'topics.csv')\n","    content_df = pd.read_csv(CFG.ROW_DIR / 'content.csv')\n","    sample_submission = pd.read_csv(CFG.ROW_DIR / 'sample_submission.csv')\n","    correlations_df = pd.read_csv(CFG.ROW_DIR / 'correlations.csv')\n","    content_df = content_df.fillna('')\n","    topics_df = topics_df.fillna('')\n","    # pathを取得する\n","    topics_df['path'] = get_path_list(topics_df)\n","    topics_df = topics_df[topics_df.has_content].reset_index(drop=True)\n","    topics_df.drop(['description', 'channel', 'category', 'level', 'parent', 'has_content'], axis = 1, inplace = True)\n","    content_df.drop(['description', 'kind',  'text', 'copyright_holder', 'license'], axis = 1, inplace = True)\n","    train_idx = topics_df[~topics_df.id.isin(sample_submission.topic_id)].index\n","    topics_df = get_train_test_data(topics_df, train_idx)\n","    topics_df.to_csv('./train_topics.csv')\n","    train_df = topics_df.join(correlations_df.content_ids.str.split(\" \").explode())\n","    train_df= train_df.reset_index(drop=True)\n","    train_df = train_df.drop_duplicates(subset=['id', 'content_ids'])\n","    train_df = train_df.rename(columns={'id':'topic_id', 'content_ids':'content_id'}).drop(columns = ['title', 'language'])\n","    train_df = train_df[train_df.fold!=-1]\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.MODEL)\n","    tokenizer.add_tokens([\"\u003c|=t_sep=|\u003e\"], special_tokens=True)\n","\n","    for fold in range(5):\n","        train_fold(train_df, tokenizer, topics_df, content_df, fold)\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1674281642731,"user":{"displayName":"松田征也","userId":"08531742653822505465"},"user_tz":-540},"id":"JhwHOUWI6ncP"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM9SwOUub/rETH3FW9TFlgt","machine_shape":"hm","mount_file_id":"1ZyI1r46SnOTN5BHABQ8mnqzy2GQCK_eG","name":"","version":""},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0121969fbcb04992a88371be50788fef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c574e0e60e546dc96d8dc3508118de0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10ce46adee8a4e6081dbc9f83e9b935e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbcd74e80a95457787e987593c14fe87","placeholder":"​","style":"IPY_MODEL_28c77842b27446878eec4308919c320d","value":"Validation DataLoader 0: 100%"}},"13bf03a138cf46cdb815be9b453f8483":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"140bc73ca0f347e28939f534c4c556cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_591ec0f355bb442fb36388ca92e34fcd","max":224,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c83f98b44f36461ea709ff87da539323","value":224}},"18491e1b44da4f328bc69a02847cc448":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19e6bc39c47d46c08a53817a823ac9e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28c77842b27446878eec4308919c320d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29dea12db9e543119e8de8938278acf4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"2a0c32c14dc74d74892612a068575d2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10ce46adee8a4e6081dbc9f83e9b935e","IPY_MODEL_140bc73ca0f347e28939f534c4c556cb","IPY_MODEL_6a87af3b6ee740cfb028cb54eb9a6557"],"layout":"IPY_MODEL_29dea12db9e543119e8de8938278acf4"}},"2e9ac0a0dd4449db9db88151b76c8085":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_59db1cf443a84ae9963f15b74250f68a","max":224,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9833867ee060439dbf0c848ede317d5b","value":224}},"37f7dbbfd99e4622847096adabdee21d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_55ace63cb0ae439590a50b6f62e5ca04","IPY_MODEL_f544fad5267546e79e9dad0de3c5af2b","IPY_MODEL_3867cd44341f431eab7526654119c7bd"],"layout":"IPY_MODEL_a409af12555e4238a86684489b0e4c2e"}},"3867cd44341f431eab7526654119c7bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_762a1b2c48974c50b92554837b9dc23c","placeholder":"​","style":"IPY_MODEL_ad1a25113a874fd687a3a54699a52a97","value":" 2/2 [00:01\u0026lt;00:00,  1.38it/s]"}},"46febb8ee63c4dc4b693968331e9a42f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e474e88fe4c44b6bf99fb2d71380777":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"55ace63cb0ae439590a50b6f62e5ca04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19e6bc39c47d46c08a53817a823ac9e3","placeholder":"​","style":"IPY_MODEL_cdf9eb39343b47699b9d7ad9972d9af5","value":"Sanity Checking DataLoader 0: 100%"}},"570264e365bd42c8a671e958e4122ae3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57201cc0a755467c89473fab21b7a393":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"591ec0f355bb442fb36388ca92e34fcd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59db1cf443a84ae9963f15b74250f68a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f56f20aaaf46bc8c94ac0b38edc76b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a87af3b6ee740cfb028cb54eb9a6557":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18491e1b44da4f328bc69a02847cc448","placeholder":"​","style":"IPY_MODEL_fb41667efc06490cba455cc658a79a2b","value":" 224/224 [00:14\u0026lt;00:00, 15.84it/s]"}},"7288528850ee495fb5ab4b6eda5430c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75094b019a8b41959b8e2b48a0f52667":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f796bcb4734b41fabc5cecf1de96f649","IPY_MODEL_2e9ac0a0dd4449db9db88151b76c8085","IPY_MODEL_b9127968424a473dbd096c87790a9f12"],"layout":"IPY_MODEL_a95a0d0dc0d842a1ad92d66c3fdd5d21"}},"762a1b2c48974c50b92554837b9dc23c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a826a7c6d64440a96fabd0ac00de223":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90acfade155c4f829a021e93bbceb1e3","placeholder":"​","style":"IPY_MODEL_60f56f20aaaf46bc8c94ac0b38edc76b","value":"Epoch 3:   2%"}},"7ef756af055945a3932f48e996331536":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aeda323a74ea4b65ba4d0c757d87e61d","IPY_MODEL_93d141ddef4c455c97f4b66c9fac25db","IPY_MODEL_9361c93b0083434097b518b74fa9debf"],"layout":"IPY_MODEL_4e474e88fe4c44b6bf99fb2d71380777"}},"8be1b676799046ef90add25b8119ca9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c59a36824f6e4b9bb85e61fde098acd3","max":1094,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46febb8ee63c4dc4b693968331e9a42f","value":23}},"8eb92a792250466e99d9ee7dd4b39de9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90acfade155c4f829a021e93bbceb1e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9361c93b0083434097b518b74fa9debf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3323da0735748cb81d264713aca589c","placeholder":"​","style":"IPY_MODEL_8eb92a792250466e99d9ee7dd4b39de9","value":" 224/224 [00:14\u0026lt;00:00, 15.85it/s]"}},"93d141ddef4c455c97f4b66c9fac25db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c574e0e60e546dc96d8dc3508118de0","max":224,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bcae1467764741679f31a4094bdbc222","value":224}},"9833867ee060439dbf0c848ede317d5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a1783e91831046689c8211d5bc5d8820":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a409af12555e4238a86684489b0e4c2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"a49e90c2e4234cee9fb5feb22dfede1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a826a7c6d64440a96fabd0ac00de223","IPY_MODEL_8be1b676799046ef90add25b8119ca9c","IPY_MODEL_e37ea76fa36643b4b9ad960bf8b9556c"],"layout":"IPY_MODEL_a9f3c36fd99a406fb48f98ffa328f8f9"}},"a95a0d0dc0d842a1ad92d66c3fdd5d21":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"a9f3c36fd99a406fb48f98ffa328f8f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"ad1a25113a874fd687a3a54699a52a97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeda323a74ea4b65ba4d0c757d87e61d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_570264e365bd42c8a671e958e4122ae3","placeholder":"​","style":"IPY_MODEL_cbd894c304e04364a2f731a35a26494e","value":"Validation DataLoader 0: 100%"}},"b9127968424a473dbd096c87790a9f12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57201cc0a755467c89473fab21b7a393","placeholder":"​","style":"IPY_MODEL_13bf03a138cf46cdb815be9b453f8483","value":" 224/224 [00:14\u0026lt;00:00, 15.88it/s]"}},"bbcd74e80a95457787e987593c14fe87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc23d27169de424bbd0b0f3bba7df69e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcae1467764741679f31a4094bdbc222":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c59a36824f6e4b9bb85e61fde098acd3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c83f98b44f36461ea709ff87da539323":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbd894c304e04364a2f731a35a26494e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdf9eb39343b47699b9d7ad9972d9af5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0ddb544a1f445148071276f65f8e620":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e37ea76fa36643b4b9ad960bf8b9556c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0ddb544a1f445148071276f65f8e620","placeholder":"​","style":"IPY_MODEL_bc23d27169de424bbd0b0f3bba7df69e","value":" 23/1094 [00:06\u0026lt;04:55,  3.62it/s, loss=0.364, v_num=21, train_loss=0.344, val_loss_step=3.300, val_loss_epoch=3.420]"}},"eae107349360454d9b95cb868929a28c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3323da0735748cb81d264713aca589c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f544fad5267546e79e9dad0de3c5af2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0121969fbcb04992a88371be50788fef","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eae107349360454d9b95cb868929a28c","value":2}},"f796bcb4734b41fabc5cecf1de96f649":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1783e91831046689c8211d5bc5d8820","placeholder":"​","style":"IPY_MODEL_7288528850ee495fb5ab4b6eda5430c2","value":"Validation DataLoader 0: 100%"}},"fb41667efc06490cba455cc658a79a2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}